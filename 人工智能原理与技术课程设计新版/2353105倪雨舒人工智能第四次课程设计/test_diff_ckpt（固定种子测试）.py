
import torch
import random
import numpy as np
from diffusers import StableDiffusionPipeline, UNet2DConditionModel
from PIL import Image
import os

# === é…ç½®å‚æ•° ===
checkpoint_path = "./Chinese_painting_model_sd/checkpoint-20000"
base_model_path = "./stable-diffusion-v1-5"
output_dir = "./generated_images_deterministic"
prompt = "ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµã€‚"
seed = 4
num_images = 1

# === åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ ===
os.makedirs(output_dir, exist_ok=True)

# === å…¨å±€å›ºå®šéšæœºæºï¼ˆç¡®ä¿å®Œå…¨å¯å¤ç°ï¼‰===
torch.manual_seed(seed)
random.seed(seed)
np.random.seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# === åŠ è½½æ¨¡å‹ ===
print("âœ… æ­£åœ¨åŠ è½½æ¨¡å‹ checkpoint...")
unet = UNet2DConditionModel.from_pretrained(f"{checkpoint_path}/unet", torch_dtype=torch.float16)
pipe = StableDiffusionPipeline.from_pretrained(base_model_path, unet=unet, torch_dtype=torch.float16)
pipe.to("cuda")

# === ç”Ÿæˆå›¾åƒ ===
print(f"ğŸ¨ å¼€å§‹ä½¿ç”¨å›ºå®šç§å­ç”Ÿæˆ {num_images} å¼ å›¾åƒ...")
for i in range(num_images):
    generator = torch.Generator(device="cuda").manual_seed(seed)
    image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5, generator=generator).images[0]
    image_path = os.path.join(output_dir, f"step20000_seed{seed}_img{i+1}.png")
    image.save(image_path)
    print(f"ğŸ–¼ï¸  å·²ä¿å­˜: {image_path}")

print("âœ… æ‰€æœ‰å›¾åƒç”Ÿæˆå®Œæ¯•ã€‚")